{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from nltk import word_tokenize, FreqDist\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recipe_Name</th>\n",
       "      <th>Recipe_Ingredients</th>\n",
       "      <th>Cuisine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bunny chow</td>\n",
       "      <td>2 tbsp vegetable oil ½ tsp cumin seeds ½ tsp f...</td>\n",
       "      <td>african</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jollof rice with fried plantains</td>\n",
       "      <td>1 tbsp olive or vegetable oil 2 large onions, ...</td>\n",
       "      <td>african</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jollof rice</td>\n",
       "      <td>400ml/14fl oz passata 3 tbsp tomato purée 2 fr...</td>\n",
       "      <td>african</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Suya fillet burger with sweet potato cubes and...</td>\n",
       "      <td>4g smoked paprika  2g cayenne pepper 6g ginger...</td>\n",
       "      <td>african</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jollof rice with chicken</td>\n",
       "      <td>300g/10½oz basmati rice 1 tbsp vegetable oil 8...</td>\n",
       "      <td>african</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Recipe_Name  \\\n",
       "0                                         Bunny chow   \n",
       "1                   Jollof rice with fried plantains   \n",
       "2                                        Jollof rice   \n",
       "3  Suya fillet burger with sweet potato cubes and...   \n",
       "4                          Jollof rice with chicken    \n",
       "\n",
       "                                  Recipe_Ingredients  Cuisine  \n",
       "0  2 tbsp vegetable oil ½ tsp cumin seeds ½ tsp f...  african  \n",
       "1  1 tbsp olive or vegetable oil 2 large onions, ...  african  \n",
       "2  400ml/14fl oz passata 3 tbsp tomato purée 2 fr...  african  \n",
       "3  4g smoked paprika  2g cayenne pepper 6g ginger...  african  \n",
       "4  300g/10½oz basmati rice 1 tbsp vegetable oil 8...  african  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv('all_recipe_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= df.drop_duplicates(subset='Recipe_Name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recipe_Name</th>\n",
       "      <th>Recipe_Ingredients</th>\n",
       "      <th>Cuisine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>475</td>\n",
       "      <td>475</td>\n",
       "      <td>475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>475</td>\n",
       "      <td>475</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Pâte sucrée (sweet shortcrust pastry)</td>\n",
       "      <td>450g/1lb lean beef mince  1 tsp crushed garlic...</td>\n",
       "      <td>caribbean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Recipe_Name  \\\n",
       "count                                     475   \n",
       "unique                                    475   \n",
       "top     Pâte sucrée (sweet shortcrust pastry)   \n",
       "freq                                        1   \n",
       "\n",
       "                                       Recipe_Ingredients    Cuisine  \n",
       "count                                                 475        475  \n",
       "unique                                                475         21  \n",
       "top     450g/1lb lean beef mince  1 tsp crushed garlic...  caribbean  \n",
       "freq                                                    1         24  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "msk = np.random.rand(len(df)) < 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "382"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = df[msk]\n",
    "len(train)\n",
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = df[~msk]\n",
    "len(test)\n",
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(382, 3)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(93, 3)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(382,)\n",
      "(382,)\n",
      "(93,)\n",
      "(93,)\n"
     ]
    }
   ],
   "source": [
    "data_train= train['Recipe_Ingredients']\n",
    "target_train= train['Cuisine']\n",
    "data_test= test['Recipe_Ingredients']\n",
    "target_test= test['Cuisine']\n",
    "print(data_train.shape)\n",
    "print(target_train.shape)\n",
    "print(data_test.shape)\n",
    "print(target_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_train=re.sub(\"[^'?a-z\\,?]\", ' ', train['Recipe_Ingredients'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/Iffy/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "\n",
    "stopwords_list = stopwords.words('english')+ list(string.punctuation)\n",
    "stopwords_list+= [\"''\", '\"\"', '...', '``']\n",
    "# regex = r\"[^'?a-z\\,?]\"\n",
    "# stopwords_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_article(article):\n",
    "    tokens = nltk.word_tokenize(article)\n",
    "    stopwords_removed = [token.lower() for token in tokens if token not in stopwords_list]\n",
    "    return stopwords_removed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('punkt')\n",
    "processed_train =  list(map(process_article, data_train))\n",
    "processed_test= list(map(process_article, data_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaned train:  ['2', 'tbsp', 'vegetable', 'oil', '½', 'tsp', 'cumin', 'seeds', '½', 'tsp', 'fennel', 'seeds', '2.5cm/1in', 'piece', 'cinnamon', 'stick', '2', 'green', 'cardamom', 'pods', '1', 'star', 'anise', '1', 'bay', 'leaf', '1', 'onion', 'finely', 'chopped', '2', 'tbsp', 'south', 'african', 'curry', 'powder', '2', 'tomatoes', 'chopped', '1kg/2lb', '2oz', 'boneless', 'leg', 'lamb', 'cut', '1.5cm/½in', 'dices', '1', 'tbsp', 'finely', 'chopped', 'fresh', 'ginger', '1', 'tbsp', 'finely', 'chopped', 'garlic', '10-12', 'curry', 'leaves', '2', 'large', 'potatoes', 'cut', 'cubes', 'size', 'meat', 'salt', '2', 'tbsp', 'finely', 'chopped', 'coriander', 'leaves', '2', 'tbsp', 'lime', 'juice', '2', 'loaves', 'crusty', 'white', 'bread', 'unsliced', 'cut', 'across', 'half', 'middle', 'crumbs', 'removed', 'coriander', 'cress', 'sprigs', 'garnish']\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "cleaned test:  ['butter', 'greasing', '400ml/14fl', 'oz', 'full-fat', 'milk', '50g/1¾oz', 'fresh', 'white', 'breadcrumbs', '4', 'large', 'free-range', 'eggs', 'beaten', '1', 'tbsp', 'olive', 'oil', '1kg/2lb', '4oz', 'lamb', 'mince', '2', 'onions', 'finely', 'chopped', '1', 'bay', 'leaf', '2', 'garlic', 'cloves', 'crushed', '2', 'tbsp', 'madras', 'curry', 'paste', '250ml/9fl', 'oz', 'lamb', 'stock', '2', 'tbsp', 'worcestershire', 'sauce', '2', 'tbsp', 'mango', 'chutney', '50g/1¾oz', 'raisins', '50g/1¾oz', 'dried', 'apricots', 'chopped', '1', 'tbsp', 'cider', 'vinegar']\n"
     ]
    }
   ],
   "source": [
    "print('cleaned train: ', processed_train[0])\n",
    "print('----'*28)\n",
    "print('cleaned test: ', processed_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22501"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern= r\"[a-z]+\"\n",
    "p= re.compile(pattern)\n",
    "ptrain= p.findall(str(processed_train))\n",
    "len(ptrain)\n",
    "# print(ptrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5376"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ptest= p.findall(str(processed_test))\n",
    "len(ptest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_concat_train = []\n",
    "for pd in processed_train:\n",
    "    articles_concat_train += pd\n",
    "articles_concat_test = []\n",
    "for pd in processed_test:\n",
    "    articles_concat_test += pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_freqdist_train = FreqDist(articles_concat_train)\n",
    "# articles_freqdist_train.most_common(200)\n",
    "articles_freqdist_test = FreqDist(articles_concat_test)\n",
    "# articles_freqdist_test.most_common(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22501, 1438)\n",
      "(5376, 1438)\n"
     ]
    }
   ],
   "source": [
    "tf_idf_ptrain = vectorizer.fit_transform(ptrain)\n",
    "tf_idf_ptest = vectorizer.transform(ptest)\n",
    "print(tf_idf_ptrain.shape)\n",
    "print(tf_idf_ptest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Number of Non-Zero Elements in Vectorized Articles: 0.9434691791475934\n",
      "Percentage of columns containing 0: 0.9993439018225677\n"
     ]
    }
   ],
   "source": [
    "non_zero_cols = tf_idf_ptrain.nnz / float(tf_idf_ptrain.shape[0])\n",
    "print(\"Average Number of Non-Zero Elements in Vectorized Articles: {}\".format(non_zero_cols))\n",
    "\n",
    "percent_sparse = 1 - (non_zero_cols / float(tf_idf_ptrain.shape[1]))\n",
    "print('Percentage of columns containing 0: {}'.format(percent_sparse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classifier = MultinomialNB()\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classifier.fit(tf_idf_ptrain, ptrain)\n",
    "nb_train_preds = nb_classifier.predict(tf_idf_ptrain)\n",
    "nb_test_preds = nb_classifier.predict(tf_idf_ptest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier.fit(tf_idf_ptrain, ptrain)\n",
    "rf_train_preds = rf_classifier.predict(tf_idf_ptrain)\n",
    "rf_test_preds = rf_classifier.predict(tf_idf_ptest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes\n",
      "Training Accuracy: 0.663 \t\t Testing Accuracy: 0.6704\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Random Forest\n",
      "Training Accuracy: 0.9956 \t\t Testing Accuracy: 0.9706\n"
     ]
    }
   ],
   "source": [
    "nb_train_score = accuracy_score(ptrain, nb_train_preds)\n",
    "nb_test_score = accuracy_score(ptest, nb_test_preds)\n",
    "rf_train_score = accuracy_score(ptrain, rf_train_preds)\n",
    "rf_test_score = accuracy_score(ptest, rf_test_preds)\n",
    "\n",
    "print(\"Multinomial Naive Bayes\")\n",
    "print(\"Training Accuracy: {:.4} \\t\\t Testing Accuracy: {:.4}\".format(nb_train_score, nb_test_score))\n",
    "print(\"\")\n",
    "print('-'*70)\n",
    "print(\"\")\n",
    "print('Random Forest')\n",
    "print(\"Training Accuracy: {:.4} \\t\\t Testing Accuracy: {:.4}\".format(rf_train_score, rf_test_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
